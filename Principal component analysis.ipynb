{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Wine</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Wine  Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0     1    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1     1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2     1    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3     1    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4     1    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('wine.csv') \n",
    "X = df.iloc[:, 1:13].values #features\n",
    "y = df.iloc[:, 0].values #class\n",
    "df.head()\n",
    "#df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 1 \n",
    "#### to standardize the features since they all are measured in different units "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler #standardscalar makes the distribution of the data to mean value 0 and standard deviation of 1\n",
    "X_std = StandardScaler().fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  step 2 \n",
    "### to find the covariance between the standardized features data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00564972,  0.09493026,  0.21273976, -0.31198788,  0.27232816,\n",
       "         0.29073446,  0.23815287, -0.15681042,  0.13747022,  0.549451  ,\n",
       "        -0.07215255,  0.07275191],\n",
       "       [ 0.09493026,  1.00564972,  0.16497228,  0.29013035, -0.05488343,\n",
       "        -0.3370606 , -0.41332866,  0.29463237, -0.22199334,  0.25039204,\n",
       "        -0.56446685, -0.37079354],\n",
       "       [ 0.21273976,  0.16497228,  1.00564972,  0.44587209,  0.28820583,\n",
       "         0.12970824,  0.11572743,  0.1872826 ,  0.00970647,  0.2603499 ,\n",
       "        -0.07508874,  0.00393333],\n",
       "       [-0.31198788,  0.29013035,  0.44587209,  1.00564972, -0.0838039 ,\n",
       "        -0.32292752, -0.353355  ,  0.36396647, -0.19844168,  0.01883781,\n",
       "        -0.27550299, -0.27833221],\n",
       "       [ 0.27232816, -0.05488343,  0.28820583, -0.0838039 ,  1.00564972,\n",
       "         0.21561254,  0.19688989, -0.25774204,  0.23777643,  0.20107967,\n",
       "         0.05571118,  0.06637684],\n",
       "       [ 0.29073446, -0.3370606 ,  0.12970824, -0.32292752,  0.21561254,\n",
       "         1.00564972,  0.86944804, -0.45247731,  0.61587304, -0.05544792,\n",
       "         0.43613151,  0.70390388],\n",
       "       [ 0.23815287, -0.41332866,  0.11572743, -0.353355  ,  0.19688989,\n",
       "         0.86944804,  1.00564972, -0.54093859,  0.65637929, -0.17335329,\n",
       "         0.54654907,  0.79164133],\n",
       "       [-0.15681042,  0.29463237,  0.1872826 ,  0.36396647, -0.25774204,\n",
       "        -0.45247731, -0.54093859,  1.00564972, -0.36791202,  0.13984265,\n",
       "        -0.26412347, -0.50611293],\n",
       "       [ 0.13747022, -0.22199334,  0.00970647, -0.19844168,  0.23777643,\n",
       "         0.61587304,  0.65637929, -0.36791202,  1.00564972, -0.02539259,\n",
       "         0.29721399,  0.52199968],\n",
       "       [ 0.549451  ,  0.25039204,  0.2603499 ,  0.01883781,  0.20107967,\n",
       "        -0.05544792, -0.17335329,  0.13984265, -0.02539259,  1.00564972,\n",
       "        -0.52476129, -0.43123763],\n",
       "       [-0.07215255, -0.56446685, -0.07508874, -0.27550299,  0.05571118,\n",
       "         0.43613151,  0.54654907, -0.26412347,  0.29721399, -0.52476129,\n",
       "         1.00564972,  0.56866303],\n",
       "       [ 0.07275191, -0.37079354,  0.00393333, -0.27833221,  0.06637684,\n",
       "         0.70390388,  0.79164133, -0.50611293,  0.52199968, -0.43123763,\n",
       "         0.56866303,  1.00564972]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_mat=np.cov(X_std.T)\n",
    "cov_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 3 \n",
    "#### find the eigenvalue and eigenvector of the covarince matrix,  the eigenvectors of the Covariance matrix are actually the directions of the axes where there is the most variance (most information) and that we call Principal Components. And eigenvalues are simply the coefficients attached to eigenvectors, which give the amount of variance carried in each Principal Component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "eig_vals, eig_vecs = np.linalg.eig(cov_mat)\n",
    "#print('Eigenvectors \\n%s' %eig_vecs)\n",
    "#print('\\nEigenvalues \\n%s' %eig_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 4\n",
    "\n",
    "#### to find the feature vector which are the matrix with columns as eigenvectors of the corresponding eigenvalues(pc) selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.42079223, 2.18758658, 1.42758975, 0.89289016, 0.82042272,\n",
       "       0.63552536, 0.55097787, 0.34868444, 0.10400644, 0.17046215,\n",
       "       0.26100162, 0.24785727])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eig_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.sum(eig_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.06779661016949"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 12)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q=np.zeros((1,12))\n",
    "for i in range(0,12):\n",
    "    q[0,i]=eig_vals[i]/p\n",
    "q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36632969, 0.18127473, 0.11829747, 0.07398949, 0.06798447,\n",
       "        0.05266292, 0.04565687, 0.0288938 , 0.00861851, 0.01412537,\n",
       "        0.02162794, 0.02053873]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q #this represents the total variation explained by the features 1,2,3 in percentage 36.6%,18.1%,11.8% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6659018898191488"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q[0,0]+q[0,1]+q[0,2] #66.59"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### the first three eigenvalues seems to be contributing more about the variance in the feature data set\n",
    "\n",
    "#### the corresponding eigenvectors are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12, 3), (178, 12))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "egvec=np.column_stack((eig_vecs[0],eig_vecs[1],eig_vecs[2]))\n",
    "egvec.shape, X_std.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step 5\n",
    "\n",
    "#### using the feature vector formed using the eigenvectors of the covariance matrix, to reorient the data from the original axes to the ones represented by the principal components, this is done by multiplying the original data set by the feature vector.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 3), (178,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = X_std.dot(egvec) \n",
    "Y.shape, y.shape # here the dimension of the data is reduced to 3 dim from 12 dim \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA using sklearn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178, 3)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "sklearn_pca = sklearnPCA(n_components=3)\n",
    "Y_sklearn = sklearn_pca.fit_transform(X_std)\n",
    "Y_sklearn.shape,y.shape\n",
    "Y_sklearn[:178, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.36632969 0.18127473 0.11829747]\n"
     ]
    }
   ],
   "source": [
    "print(sklearn_pca.explained_variance_ratio_)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCR using multinomial logistic regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 2 1 1 1 1 1 1 1 1 1\n",
      " 2 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 1 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0.9550561797752809\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015616416931152344"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(Y_sklearn, y)\n",
    "print(clf.predict(Y_sklearn[:178, :]))\n",
    "clf.predict_proba(Y_sklearn[:178, :])\n",
    "print(clf.score(Y_sklearn, y))\n",
    "time=(time.time() - start_time)\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multinomial logistic regression on all the predictors/feature wine data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 1 1 1 1 2 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 3 2 2 2 2 1 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
      " 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3]\n",
      "0.9719101123595506\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.047966957092285156"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "start_time1=time.time()\n",
    "clf = LogisticRegression(random_state=0, solver='lbfgs',multi_class='multinomial').fit(X, y)\n",
    "print(clf.predict(X[:178, :]))\n",
    "clf.predict_proba(X[:1778, :]) \n",
    "print(clf.score(X, y))\n",
    "time1=(time.time()-start_time1)\n",
    "time1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
